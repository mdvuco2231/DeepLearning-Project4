{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6ba053e8-918d-4709-8eeb-2be96c331126",
   "metadata": {},
   "source": [
    "# Project 4: Getting Started with NLP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8de3f86-0b4c-402a-8194-7fd739ac04a5",
   "metadata": {},
   "source": [
    "## Step 1: Load in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "882195e5-b35b-4e56-ac36-7c437b1d578c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   id keyword location                                               text  \\\n",
      "0   1     NaN      NaN  Our Deeds are the Reason of this #earthquake M...   \n",
      "1   4     NaN      NaN             Forest fire near La Ronge Sask. Canada   \n",
      "2   5     NaN      NaN  All residents asked to 'shelter in place' are ...   \n",
      "3   6     NaN      NaN  13,000 people receive #wildfires evacuation or...   \n",
      "4   7     NaN      NaN  Just got sent this photo from Ruby #Alaska as ...   \n",
      "\n",
      "   target  \n",
      "0       1  \n",
      "1       1  \n",
      "2       1  \n",
      "3       1  \n",
      "4       1  \n",
      "Train shape: (7613, 5), Test shape: (3263, 4)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# load data\n",
    "train_df = pd.read_csv(\"nlp-getting-started/train.csv\")\n",
    "test_df = pd.read_csv(\"nlp-getting-started/test.csv\")\n",
    "\n",
    "print(train_df.head())\n",
    "print(f\"Train shape: {train_df.shape}, Test shape: {test_df.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7278008-7749-44e3-aba5-aeaecfb8bc79",
   "metadata": {},
   "source": [
    "## Step 2: Clean the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "06fc9f77-8649-42ef-96fe-d2af6f001466",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                text  \\\n",
      "0  Our Deeds are the Reason of this #earthquake M...   \n",
      "1             Forest fire near La Ronge Sask. Canada   \n",
      "2  All residents asked to 'shelter in place' are ...   \n",
      "3  13,000 people receive #wildfires evacuation or...   \n",
      "4  Just got sent this photo from Ruby #Alaska as ...   \n",
      "\n",
      "                                          clean_text  \n",
      "0       deeds reason earthquake may allah forgive us  \n",
      "1              forest fire near la ronge sask canada  \n",
      "2  residents asked shelter place notified officer...  \n",
      "3  people receive wildfires evacuation orders cal...  \n",
      "4  got sent photo ruby alaska smoke wildfires pou...  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/marcvucovich/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "nltk.download('stopwords')\n",
    "STOPWORDS = set(stopwords.words('english'))\n",
    "\n",
    "def clean_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"http\\S+|www\\S+|https\\S+\", \"\", text)  \n",
    "    text = re.sub(r'\\@w+|\\#', '', text)  \n",
    "    text = re.sub(r'\\d+', '', text)  \n",
    "    text = re.sub(r'[^a-zA-Z!? ]', '', text)  \n",
    "    text = \" \".join([word for word in text.split() if word not in STOPWORDS]) \n",
    "    return text\n",
    "\n",
    "\n",
    "#clean data\n",
    "train_df[\"clean_text\"] = train_df[\"text\"].apply(clean_text)\n",
    "test_df[\"clean_text\"] = test_df[\"text\"].apply(clean_text)\n",
    "\n",
    "print(train_df[[\"text\", \"clean_text\"]].head(5))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1438d924-1897-4470-abe5-441bb569161f",
   "metadata": {},
   "source": [
    "## Step 3: Pre-process the data and create tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a72ce103-7ff0-471f-9279-cabff1a5dbe2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample sequence: [4231, 740, 147, 57, 1552, 4232, 13]\n",
      "Padded shape: (7613, 50)\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "\n",
    "MAX_VOCAB = 10000  \n",
    "MAX_LENGTH = 50  \n",
    "\n",
    "#init tokenizer\n",
    "tokenizer = Tokenizer(num_words=MAX_VOCAB, oov_token=\"<OOV>\")\n",
    "tokenizer.fit_on_texts(train_df[\"clean_text\"])\n",
    "word_index = tokenizer.word_index \n",
    "\n",
    "#text to sequences\n",
    "train_sequences = tokenizer.texts_to_sequences(train_df[\"clean_text\"])\n",
    "test_sequences = tokenizer.texts_to_sequences(test_df[\"clean_text\"])\n",
    "\n",
    "#pad sequences\n",
    "X_train = pad_sequences(train_sequences, maxlen=MAX_LENGTH, padding=\"post\", truncating=\"post\")\n",
    "X_test = pad_sequences(test_sequences, maxlen=MAX_LENGTH, padding=\"post\", truncating=\"post\")\n",
    "\n",
    "# add labels\n",
    "y_train = train_df[\"target\"].values  \n",
    "\n",
    "print(f\"Sample sequence: {train_sequences[0]}\")\n",
    "print(f\"Padded shape: {X_train.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79792085-1a26-4184-8267-841bd2884816",
   "metadata": {},
   "source": [
    "## Step 4: Create the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b6485ddb-27d0-47b5-a77b-c9644f001828",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Cellar/jupyterlab/4.1.6_1/libexec/lib/python3.12/site-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)         │       <span style=\"color: #00af00; text-decoration-color: #00af00\">849,850</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ spatial_dropout1d               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SpatialDropout1D</span>)              │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">9,664</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)        │       <span style=\"color: #00af00; text-decoration-color: #00af00\">197,632</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">164,352</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ layer_normalization             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m50\u001b[0m)         │       \u001b[38;5;34m849,850\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ spatial_dropout1d               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m50\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mSpatialDropout1D\u001b[0m)              │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d (\u001b[38;5;33mConv1D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │         \u001b[38;5;34m9,664\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d (\u001b[38;5;33mMaxPooling1D\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional (\u001b[38;5;33mBidirectional\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m256\u001b[0m)        │       \u001b[38;5;34m197,632\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_1 (\u001b[38;5;33mBidirectional\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │       \u001b[38;5;34m164,352\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ layer_normalization             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │           \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mLayerNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m8,256\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m65\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,230,075</span> (4.69 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,230,075\u001b[0m (4.69 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">380,225</span> (1.45 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m380,225\u001b[0m (1.45 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">849,850</span> (3.24 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m849,850\u001b[0m (3.24 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Bidirectional, Dense, Dropout, SpatialDropout1D, Conv1D, MaxPooling1D, LayerNormalization\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def load_glove_embeddings(filepath, word_index, embedding_dim=50):\n",
    "    embeddings_index = {}\n",
    "\n",
    "    #read glove file\n",
    "    with open(filepath, encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            values = line.split()\n",
    "            word = values[0] \n",
    "            coeffs = np.asarray(values[1:], dtype=\"float32\") \n",
    "            embeddings_index[word] = coeffs\n",
    "\n",
    "    vocab_size = len(word_index) + 1  \n",
    "    embedding_matrix = np.zeros((vocab_size, embedding_dim))\n",
    "\n",
    "    for word, i in word_index.items():\n",
    "        vector = embeddings_index.get(word)  \n",
    "        if vector is not None:  \n",
    "            embedding_matrix[i] = vector\n",
    "\n",
    "    return embedding_matrix\n",
    "\n",
    "\n",
    "# load glove embeddings\n",
    "EMBEDDING_DIM = 50\n",
    "EMBEDDING_PATH = \"glove/glove.6B.50d.txt\"\n",
    "embedding_matrix = load_glove_embeddings(EMBEDDING_PATH, tokenizer.word_index, EMBEDDING_DIM)\n",
    "\n",
    "# init model\n",
    "model = Sequential([\n",
    "    Embedding(input_dim=len(tokenizer.word_index) + 1, \n",
    "              output_dim=EMBEDDING_DIM, \n",
    "              input_length=MAX_LENGTH, \n",
    "              weights=[embedding_matrix], \n",
    "              trainable=False), \n",
    "\n",
    "    SpatialDropout1D(0.3),\n",
    "\n",
    "    Conv1D(filters=64, kernel_size=3, activation=\"relu\", padding=\"same\"),  \n",
    "    MaxPooling1D(pool_size=2),\n",
    "\n",
    "    Bidirectional(LSTM(128, return_sequences=True, dropout=0.2, recurrent_dropout=0.2)),\n",
    "    Bidirectional(LSTM(64, dropout=0.2, recurrent_dropout=0.2)),\n",
    "\n",
    "    LayerNormalization(),\n",
    "\n",
    "    Dense(64, activation=\"relu\"),\n",
    "    Dropout(0.3),\n",
    "    Dense(1, activation=\"sigmoid\")  \n",
    "])\n",
    "\n",
    "\n",
    "model.compile(\n",
    "    loss=\"binary_crossentropy\", \n",
    "    optimizer=Adam(learning_rate=1e-4),  \n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "model.build(input_shape=(None, MAX_LENGTH))\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81792198-1a8a-47d2-a28c-2c5bc0304bf1",
   "metadata": {},
   "source": [
    "## Step 5: Train the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "730b668f-2109-4b67-83a7-623032afe217",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 31ms/step - accuracy: 0.5592 - loss: 0.7266 - val_accuracy: 0.7833 - val_loss: 0.4981\n",
      "Epoch 2/20\n",
      "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 35ms/step - accuracy: 0.7128 - loss: 0.5677 - val_accuracy: 0.7905 - val_loss: 0.4806\n",
      "Epoch 3/20\n",
      "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 36ms/step - accuracy: 0.7432 - loss: 0.5416 - val_accuracy: 0.7951 - val_loss: 0.4533\n",
      "Epoch 4/20\n",
      "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 36ms/step - accuracy: 0.7511 - loss: 0.5181 - val_accuracy: 0.7991 - val_loss: 0.4508\n",
      "Epoch 5/20\n",
      "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 36ms/step - accuracy: 0.7501 - loss: 0.5257 - val_accuracy: 0.7965 - val_loss: 0.4469\n",
      "Epoch 6/20\n",
      "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 36ms/step - accuracy: 0.7671 - loss: 0.5137 - val_accuracy: 0.7958 - val_loss: 0.4555\n",
      "Epoch 7/20\n",
      "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 36ms/step - accuracy: 0.7585 - loss: 0.5144 - val_accuracy: 0.8056 - val_loss: 0.4409\n",
      "Epoch 8/20\n",
      "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 36ms/step - accuracy: 0.7678 - loss: 0.4990 - val_accuracy: 0.8037 - val_loss: 0.4429\n",
      "Epoch 9/20\n",
      "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 36ms/step - accuracy: 0.7633 - loss: 0.5087 - val_accuracy: 0.8037 - val_loss: 0.4481\n",
      "Epoch 10/20\n",
      "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 37ms/step - accuracy: 0.7707 - loss: 0.4919 - val_accuracy: 0.8017 - val_loss: 0.4427\n",
      "Epoch 11/20\n",
      "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 36ms/step - accuracy: 0.7664 - loss: 0.4968 - val_accuracy: 0.7978 - val_loss: 0.4481\n",
      "Epoch 12/20\n",
      "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 36ms/step - accuracy: 0.7731 - loss: 0.4876 - val_accuracy: 0.8011 - val_loss: 0.4367\n",
      "Epoch 13/20\n",
      "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 36ms/step - accuracy: 0.7616 - loss: 0.5015 - val_accuracy: 0.7958 - val_loss: 0.4557\n",
      "Epoch 14/20\n",
      "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 36ms/step - accuracy: 0.7780 - loss: 0.4755 - val_accuracy: 0.8030 - val_loss: 0.4396\n",
      "Epoch 15/20\n",
      "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 36ms/step - accuracy: 0.7729 - loss: 0.4916 - val_accuracy: 0.8043 - val_loss: 0.4362\n",
      "Epoch 16/20\n",
      "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 36ms/step - accuracy: 0.7699 - loss: 0.4936 - val_accuracy: 0.8004 - val_loss: 0.4418\n",
      "Epoch 17/20\n",
      "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 36ms/step - accuracy: 0.7754 - loss: 0.4868 - val_accuracy: 0.8030 - val_loss: 0.4301\n",
      "Epoch 18/20\n",
      "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 36ms/step - accuracy: 0.7759 - loss: 0.4821 - val_accuracy: 0.8024 - val_loss: 0.4364\n",
      "Epoch 19/20\n",
      "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 36ms/step - accuracy: 0.7766 - loss: 0.4817 - val_accuracy: 0.8056 - val_loss: 0.4354\n",
      "Epoch 20/20\n",
      "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 36ms/step - accuracy: 0.7769 - loss: 0.4799 - val_accuracy: 0.8063 - val_loss: 0.4342\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=20, \n",
    "    batch_size=32,\n",
    "    validation_split=0.2,\n",
    "    verbose=1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "86d40e99-460f-4518-a04c-5189654167f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.8162 - loss: 0.4127\n",
      "Train Accuracy: 80.56%\n"
     ]
    }
   ],
   "source": [
    "# eval\n",
    "loss, acc = model.evaluate(X_train, y_train)\n",
    "print(f\"Train Accuracy: {acc:.2%}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0f4786c-0a5a-498c-8dcb-b549ffdc1115",
   "metadata": {},
   "source": [
    "## Step 6: Validate "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1983b662-f0c9-4e72-812d-caa51fce3686",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step\n",
      "Predictions saved!\n"
     ]
    }
   ],
   "source": [
    "#predict on test data\n",
    "predictions = model.predict(X_test)\n",
    "predictions = (predictions > 0.5).astype(int)  \n",
    "\n",
    "# save\n",
    "test_df[\"target\"] = predictions\n",
    "test_df[[\"id\", \"target\"]].to_csv(\"submission.csv\", index=False)\n",
    "print(\"Predictions saved!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c4027b0-4785-4a0f-95ec-f3496b94923b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f88f5bc-0662-4c8c-b965-c6610ace64d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7515912e-e800-4dec-84a0-1c1398134acf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efa40a75-86f3-430e-b0c8-26e1e0bc42a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65923827-dc10-4c4c-9429-017dcdae54fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b7905e1-ad32-44e8-8607-1fa634b2be4b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4de73831-f3a3-480d-8114-bbde1dccf572",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5efe979d-681b-45a4-9d25-7e7f6450293b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
